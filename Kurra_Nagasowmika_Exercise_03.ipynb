{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7441d4f2-c25b-45f2-947d-086ad9c2363a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nHere is an example of a text classification task and potential features for model building:\\n\\n1.Bag of Words (BoW) Model:\\nExplanation: Representing each review as a vector of word frequencies provides insight into the most important words used by customers.\\nWhy it\\'s helpful: High-frequency words in positive reviews might include terms like \"love,\" \"excellent,\" or \"amazing,\" while negative reviews may contain words like \"disappointing,\" \"problems,\" or \"poor.\"\\n\\n2.TF-IDF (Term Frequency-Inverse Document Frequency) Features:\\nExplanation: Similar to BoW, but with TF-IDF weights, emphasizing the importance of words rare in the entire dataset but frequent in a specific review.\\nWhy it\\'s helpful: It helps identify words that are distinctive to certain reviews, providing context on specific aspects of products that customers find noteworthy.\\n\\n3.Emoticons and Emoji Features:\\nExplanation: Extracting emoticons and emojis can capture the emotional tone of the review.\\nWhy it\\'s helpful: Emoticons like ðŸ˜Š or emojis like ðŸŽ‰ often indicate positive sentiments, while ðŸ˜¡ or ðŸ˜ž may signify negative sentiments.\\n\\n4.N-grams (2-grams) Features:\\nExplanation: Considering pairs of consecutive words (2-grams) helps capture phrases and expressions.\\nWhy it\\'s helpful: Some sentiments may be conveyed through specific phrases, and capturing 2-grams can provide context that single words may miss.\\n\\n5.Product-specific Lexicon Features:\\nExplanation: Counting occurrences of product-related words in sentiment lexicons (e.g., \"quality,\" \"service,\" \"price\").\\nWhy it\\'s helpful: Understanding sentiments related to specific product aspects allows businesses to pinpoint areas for improvement or highlight strengths.\\n\\n6.Part-of-Speech (POS) Tags Features:\\nExplanation: Tagging words with their parts of speech provides insights into the grammatical structure of reviews.\\nWhy it\\'s helpful: Identifying adjectives in positive reviews (e.g., \"great,\" \"awesome\") or negative reviews (e.g., \"bad,\" \"poor\") helps understand the linguistic patterns associated with sentiments.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Here is an example of a text classification task and potential features for model building:\n",
        "\n",
        "1.Bag of Words (BoW) Model:\n",
        "Explanation: Representing each review as a vector of word frequencies provides insight into the most important words used by customers.\n",
        "Why it's helpful: High-frequency words in positive reviews might include terms like \"love,\" \"excellent,\" or \"amazing,\" while negative reviews may contain words like \"disappointing,\" \"problems,\" or \"poor.\"\n",
        "\n",
        "2.TF-IDF (Term Frequency-Inverse Document Frequency) Features:\n",
        "Explanation: Similar to BoW, but with TF-IDF weights, emphasizing the importance of words rare in the entire dataset but frequent in a specific review.\n",
        "Why it's helpful: It helps identify words that are distinctive to certain reviews, providing context on specific aspects of products that customers find noteworthy.\n",
        "\n",
        "3.Emoticons and Emoji Features:\n",
        "Explanation: Extracting emoticons and emojis can capture the emotional tone of the review.\n",
        "Why it's helpful: Emoticons like ðŸ˜Š or emojis like ðŸŽ‰ often indicate positive sentiments, while ðŸ˜¡ or ðŸ˜ž may signify negative sentiments.\n",
        "\n",
        "4.N-grams (2-grams) Features:\n",
        "Explanation: Considering pairs of consecutive words (2-grams) helps capture phrases and expressions.\n",
        "Why it's helpful: Some sentiments may be conveyed through specific phrases, and capturing 2-grams can provide context that single words may miss.\n",
        "\n",
        "5.Product-specific Lexicon Features:\n",
        "Explanation: Counting occurrences of product-related words in sentiment lexicons (e.g., \"quality,\" \"service,\" \"price\").\n",
        "Why it's helpful: Understanding sentiments related to specific product aspects allows businesses to pinpoint areas for improvement or highlight strengths.\n",
        "\n",
        "6.Part-of-Speech (POS) Tags Features:\n",
        "Explanation: Tagging words with their parts of speech provides insights into the grammatical structure of reviews.\n",
        "Why it's helpful: Identifying adjectives in positive reviews (e.g., \"great,\" \"awesome\") or negative reviews (e.g., \"bad,\" \"poor\") helps understand the linguistic patterns associated with sentiments.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Sample text data for sentiment analysis\n",
        "sample_text = [\n",
        "    \"Absolutely enamored with this product! It's a game-changer.\",\n",
        "    \"I despise this, it's a complete disappointment.\",\n",
        "    \"Sharing a neutral opinion with no strong sentiment attached.\",\n",
        "    \"ðŸ˜Š Exceptional experience with their customer service! ðŸ˜ƒ\",\n",
        "    \"I'm appalled at how dreadful this is. ðŸ˜¡\",\n",
        "    \"Just received my order and it's perfect! ðŸŽ‰\",\n",
        "    \"This new feature is amazing! Can't wait to explore it. ðŸ”¥\",\n",
        "    \"Feeling frustrated with the app's performance today. ðŸ˜¤\",\n",
        "    \"Spent the day outdoors, feeling blissful and content. ðŸŒžðŸ˜Œ\",\n",
        "]\n",
        "\n",
        "# Downloading the required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# setting up the stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to  the preprocess input text: lowercase conversion, tokenization, and stopwords removal\n",
        "def custom_preprocess(input_text):\n",
        "    processed_text = input_text.lower()\n",
        "    tokenized_text = word_tokenize(processed_text)\n",
        "    filtered_tokens = [word for word in tokenized_text if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "# Applying custom text for pre-processing to the sample data\n",
        "custom_processed_text = [custom_preprocess(text) for text in sample_text]\n",
        "\n",
        "# 1. Bag of Words (BoW) Model:-\n",
        "word_count_vectorizer = CountVectorizer()\n",
        "word_count_features = word_count_vectorizer.fit_transform(custom_processed_text)\n",
        "word_count_df = pd.DataFrame(word_count_features.toarray(), columns=word_count_vectorizer.get_feature_names_out())\n",
        "print(\"\\nWord Count Features:\")\n",
        "print(word_count_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzwrlpXNyYcQ",
        "outputId": "b0299f88-5635-4cb8-d18f-4f0d43ca502c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Count Features:\n",
            "   absolutely  amazing  app  appalled  attached  blissful  ca  changer  \\\n",
            "0           1        0    0         0         0         0   0        1   \n",
            "1           0        0    0         0         0         0   0        0   \n",
            "2           0        0    0         0         1         0   0        0   \n",
            "3           0        0    0         0         0         0   0        0   \n",
            "4           0        0    0         1         0         0   0        0   \n",
            "5           0        0    0         0         0         0   0        0   \n",
            "6           0        1    0         0         0         0   1        0   \n",
            "7           0        0    1         0         0         0   0        0   \n",
            "8           0        0    0         0         0         1   0        0   \n",
            "\n",
            "   complete  content  ...  performance  product  received  sentiment  service  \\\n",
            "0         0        0  ...            0        1         0          0        0   \n",
            "1         1        0  ...            0        0         0          0        0   \n",
            "2         0        0  ...            0        0         0          1        0   \n",
            "3         0        0  ...            0        0         0          0        1   \n",
            "4         0        0  ...            0        0         0          0        0   \n",
            "5         0        0  ...            0        0         1          0        0   \n",
            "6         0        0  ...            0        0         0          0        0   \n",
            "7         0        0  ...            1        0         0          0        0   \n",
            "8         0        1  ...            0        0         0          0        0   \n",
            "\n",
            "   sharing  spent  strong  today  wait  \n",
            "0        0      0       0      0     0  \n",
            "1        0      0       0      0     0  \n",
            "2        1      0       1      0     0  \n",
            "3        0      0       0      0     0  \n",
            "4        0      0       0      0     0  \n",
            "5        0      0       0      0     0  \n",
            "6        0      0       0      0     1  \n",
            "7        0      0       0      1     0  \n",
            "8        0      1       0      0     0  \n",
            "\n",
            "[9 rows x 39 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. TF-IDF Model\n",
        "new_tfidf_model = TfidfVectorizer()\n",
        "new_tfidf_data = new_tfidf_model.fit_transform(custom_processed_text)\n",
        "new_tfidf_dataframe = pd.DataFrame(new_tfidf_data.toarray(), columns=new_tfidf_model.get_feature_names_out())\n",
        "print(\"\\nNew TF-IDF Features:\")\n",
        "print(new_tfidf_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoO5HlHs2hxf",
        "outputId": "b94dc2fc-0925-4988-b31f-fdc01c53fef2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New TF-IDF Features:\n",
            "   absolutely   amazing       app  appalled  attached  blissful        ca  \\\n",
            "0    0.447214  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "2    0.000000  0.000000  0.000000  0.000000  0.408248  0.000000  0.000000   \n",
            "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "4    0.000000  0.000000  0.000000  0.707107  0.000000  0.000000  0.000000   \n",
            "5    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "6    0.000000  0.408248  0.000000  0.000000  0.000000  0.000000  0.408248   \n",
            "7    0.000000  0.000000  0.460611  0.000000  0.000000  0.000000  0.000000   \n",
            "8    0.000000  0.000000  0.000000  0.000000  0.000000  0.418363  0.000000   \n",
            "\n",
            "    changer  complete   content  ...  performance   product  received  \\\n",
            "0  0.447214   0.00000  0.000000  ...     0.000000  0.447214   0.00000   \n",
            "1  0.000000   0.57735  0.000000  ...     0.000000  0.000000   0.00000   \n",
            "2  0.000000   0.00000  0.000000  ...     0.000000  0.000000   0.00000   \n",
            "3  0.000000   0.00000  0.000000  ...     0.000000  0.000000   0.00000   \n",
            "4  0.000000   0.00000  0.000000  ...     0.000000  0.000000   0.00000   \n",
            "5  0.000000   0.00000  0.000000  ...     0.000000  0.000000   0.57735   \n",
            "6  0.000000   0.00000  0.000000  ...     0.000000  0.000000   0.00000   \n",
            "7  0.000000   0.00000  0.000000  ...     0.460611  0.000000   0.00000   \n",
            "8  0.000000   0.00000  0.418363  ...     0.000000  0.000000   0.00000   \n",
            "\n",
            "   sentiment  service   sharing     spent    strong     today      wait  \n",
            "0   0.000000      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1   0.000000      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2   0.408248      0.0  0.408248  0.000000  0.408248  0.000000  0.000000  \n",
            "3   0.000000      0.5  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "4   0.000000      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "5   0.000000      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "6   0.000000      0.0  0.000000  0.000000  0.000000  0.000000  0.408248  \n",
            "7   0.000000      0.0  0.000000  0.000000  0.000000  0.460611  0.000000  \n",
            "8   0.000000      0.0  0.000000  0.418363  0.000000  0.000000  0.000000  \n",
            "\n",
            "[9 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Emoticons and Emoji Analysis\n",
        "def emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\"u\"\\U0001F600-\\U0001F64F\" \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.findall(text)\n",
        "emoji_features = [emojis(text) for text in sample_text]\n",
        "emoji_df = pd.DataFrame({'Emoji Features': emoji_features})\n",
        "print(\"\\nEmoticon and Emoji Features:\")\n",
        "print(emoji_df)"
      ],
      "metadata": {
        "id": "8DSmn6Xw2k6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. N-grams (2-grams) Model\n",
        "ngram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "ngram_features = ngram_vectorizer.fit_transform(custom_processed_text)\n",
        "ngram_df = pd.DataFrame(ngram_features.toarray(), columns=ngram_vectorizer.get_feature_names_out())\n",
        "print(\"\\n2-gram Features:\")\n",
        "print(ngram_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ_82VMj2qOg",
        "outputId": "18fd65de-ec28-411b-f01c-66a800fb28ad"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2-gram Features:\n",
            "   absolutely enamored  amazing ca  app performance  appalled dreadful  \\\n",
            "0                    1           0                0                  0   \n",
            "1                    0           0                0                  0   \n",
            "2                    0           0                0                  0   \n",
            "3                    0           0                0                  0   \n",
            "4                    0           0                0                  1   \n",
            "5                    0           0                0                  0   \n",
            "6                    0           1                0                  0   \n",
            "7                    0           0                1                  0   \n",
            "8                    0           0                0                  0   \n",
            "\n",
            "   blissful content  ca wait  complete disappointment  customer service  \\\n",
            "0                 0        0                        0                 0   \n",
            "1                 0        0                        1                 0   \n",
            "2                 0        0                        0                 0   \n",
            "3                 0        0                        0                 1   \n",
            "4                 0        0                        0                 0   \n",
            "5                 0        0                        0                 0   \n",
            "6                 0        1                        0                 0   \n",
            "7                 0        0                        0                 0   \n",
            "8                 1        0                        0                 0   \n",
            "\n",
            "   day outdoors  despise complete  ...  order perfect  outdoors feeling  \\\n",
            "0             0                 0  ...              0                 0   \n",
            "1             0                 1  ...              0                 0   \n",
            "2             0                 0  ...              0                 0   \n",
            "3             0                 0  ...              0                 0   \n",
            "4             0                 0  ...              0                 0   \n",
            "5             0                 0  ...              1                 0   \n",
            "6             0                 0  ...              0                 0   \n",
            "7             0                 0  ...              0                 0   \n",
            "8             1                 0  ...              0                 1   \n",
            "\n",
            "   performance today  product game  received order  sentiment attached  \\\n",
            "0                  0             1               0                   0   \n",
            "1                  0             0               0                   0   \n",
            "2                  0             0               0                   1   \n",
            "3                  0             0               0                   0   \n",
            "4                  0             0               0                   0   \n",
            "5                  0             0               1                   0   \n",
            "6                  0             0               0                   0   \n",
            "7                  1             0               0                   0   \n",
            "8                  0             0               0                   0   \n",
            "\n",
            "   sharing neutral  spent day  strong sentiment  wait explore  \n",
            "0                0          0                 0             0  \n",
            "1                0          0                 0             0  \n",
            "2                1          0                 1             0  \n",
            "3                0          0                 0             0  \n",
            "4                0          0                 0             0  \n",
            "5                0          0                 0             0  \n",
            "6                0          0                 0             1  \n",
            "7                0          0                 0             0  \n",
            "8                0          1                 0             0  \n",
            "\n",
            "[9 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Product-specific Lexicon Features\n",
        "\n",
        "pos_lexicon = [\"enamored\", \"game-changer\", \"exceptional\"]\n",
        "neg_lexicon = [\"despise\", \"dreadful\", \"disappointment\"]\n",
        "# Function to count occurrences of words\n",
        "def count_words(text, lexicon):\n",
        "    words = text.split()\n",
        "    count = sum(1 for word in words if word in lexicon)\n",
        "    return count\n",
        "pos_lexicon_features = [count_words(text, pos_lexicon) for text in custom_processed_text]\n",
        "neg_lexicon_features = [count_words(text, neg_lexicon) for text in custom_processed_text]\n",
        "lexicon_df = pd.DataFrame({'Positive Lexicon Features': pos_lexicon_features,\n",
        "                           'Negative Lexicon Features': neg_lexicon_features})\n",
        "print(\"\\nSentiment Lexicon Features:\")\n",
        "print(lexicon_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynxwk9MT2oW-",
        "outputId": "153424eb-1f75-4ea7-96d3-2e1913a412fb"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment Lexicon Features:\n",
            "   Positive Lexicon Features  Negative Lexicon Features\n",
            "0                          2                          0\n",
            "1                          0                          2\n",
            "2                          0                          0\n",
            "3                          1                          0\n",
            "4                          0                          1\n",
            "5                          0                          0\n",
            "6                          0                          0\n",
            "7                          0                          0\n",
            "8                          0                          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Part-of-Speech (POS) Tags Features:\n",
        "pos_tags = [nltk.pos_tag(word_tokenize(text)) for text in custom_processed_text]\n",
        "print(\"\\nPart-of-Speech (POS) Tags:\")\n",
        "for tags in pos_tags:\n",
        "    print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8cYkWfd2vSR",
        "outputId": "892801d3-53a8-4dfd-8afe-e00c29413f03"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Part-of-Speech (POS) Tags:\n",
            "[('absolutely', 'RB'), ('enamored', 'JJ'), ('product', 'NN'), ('!', '.'), (\"'s\", 'POS'), ('game-changer', 'NN'), ('.', '.')]\n",
            "[('despise', 'NN'), (',', ','), (\"'s\", 'POS'), ('complete', 'JJ'), ('disappointment', 'NN'), ('.', '.')]\n",
            "[('sharing', 'VBG'), ('neutral', 'JJ'), ('opinion', 'NN'), ('strong', 'JJ'), ('sentiment', 'NN'), ('attached', 'VBN'), ('.', '.')]\n",
            "[('ðŸ˜Š', 'JJ'), ('exceptional', 'JJ'), ('experience', 'NN'), ('customer', 'NN'), ('service', 'NN'), ('!', '.'), ('ðŸ˜ƒ', 'NN')]\n",
            "[(\"'m\", 'VBP'), ('appalled', 'JJ'), ('dreadful', 'NN'), ('.', '.'), ('ðŸ˜¡', 'NN')]\n",
            "[('received', 'VBN'), ('order', 'NN'), (\"'s\", 'POS'), ('perfect', 'NN'), ('!', '.'), ('ðŸŽ‰', 'NN')]\n",
            "[('new', 'JJ'), ('feature', 'NN'), ('amazing', 'NN'), ('!', '.'), ('ca', 'MD'), (\"n't\", 'RB'), ('wait', 'VB'), ('explore', 'RB'), ('.', '.'), ('ðŸ”¥', 'VB')]\n",
            "[('feeling', 'VBG'), ('frustrated', 'VBD'), ('app', 'NN'), (\"'s\", 'POS'), ('performance', 'NN'), ('today', 'NN'), ('.', '.'), ('ðŸ˜¤', 'NN')]\n",
            "[('spent', 'JJ'), ('day', 'NN'), ('outdoors', 'NNS'), (',', ','), ('feeling', 'VBG'), ('blissful', 'JJ'), ('content', 'NN'), ('.', '.'), ('ðŸŒžðŸ˜Œ', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018dbc34-97cc-4cf4-867b-5debceb7b8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Features:\n",
            "1: Feature 22\n",
            "2: Feature 12\n",
            "3: Feature 6\n",
            "4: Feature 17\n",
            "5: Feature 35\n",
            "6: Feature 29\n",
            "7: Feature 25\n",
            "8: Feature 36\n",
            "9: Feature 46\n",
            "10: Feature 20\n",
            "11: Feature 5\n",
            "12: Feature 21\n",
            "13: Feature 30\n",
            "14: Feature 31\n",
            "15: Feature 11\n",
            "16: Feature 33\n",
            "17: Feature 23\n",
            "18: Feature 14\n",
            "19: Feature 15\n",
            "20: Feature 47\n",
            "21: Feature 13\n",
            "22: Feature 10\n",
            "23: Feature 9\n",
            "24: Feature 8\n",
            "25: Feature 7\n",
            "26: Feature 4\n",
            "27: Feature 3\n",
            "28: Feature 2\n",
            "29: Feature 16\n",
            "30: Feature 24\n",
            "31: Feature 18\n",
            "32: Feature 39\n",
            "33: Feature 45\n",
            "34: Feature 44\n",
            "35: Feature 43\n",
            "36: Feature 42\n",
            "37: Feature 41\n",
            "38: Feature 40\n",
            "39: Feature 38\n",
            "40: Feature 19\n",
            "41: Feature 37\n",
            "42: Feature 34\n",
            "43: Feature 32\n",
            "44: Feature 28\n",
            "45: Feature 27\n",
            "46: Feature 26\n",
            "47: Feature 1\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "import numpy as np\n",
        "\n",
        "# Sample texts\n",
        "texts = [\n",
        "    \"I love this product! It's amazing.\",\n",
        "    \"This is terrible, I hate it!\",\n",
        "    \"Neutral comment with no strong feelings.\",\n",
        "    \"ðŸ˜Š Great experience with their customer service! ðŸ˜ƒ\",\n",
        "    \"I can't believe how bad this is. ðŸ˜¡\",\n",
        "    \"Just received my order and it's perfect! ðŸŽ‰\",\n",
        "    \"This new feature is amazing! Can't wait to explore it. ðŸ”¥\",\n",
        "    \"Feeling frustrated with the app's performance today. ðŸ˜¤\",\n",
        "    \"Spent the day outdoors, feeling blissful and content. ðŸŒžðŸ˜Œ\",\n",
        "]\n",
        "\n",
        "# Labels\n",
        "labels = [1, 0, 2, 1, 0, 1, 1, 0, 2]\n",
        "\n",
        "# Preprocess texts\n",
        "preprocessed_texts = [preprocess_text(text) for text in texts]\n",
        "\n",
        "# Define emojis\n",
        "emojis = ['ðŸ˜Š','ðŸ˜ƒ','ðŸ˜¡','ðŸŽ‰','ðŸ”¥','ðŸ˜¤','ðŸŒž','ðŸ˜Œ']\n",
        "\n",
        "# Get emoji features\n",
        "emoji_features = [[1 if emoji in text else 0 for emoji in emojis] for text in texts]\n",
        "\n",
        "# Combine features\n",
        "feature_matrix = np.concatenate((word_count_features.toarray(), emoji_features), axis=1)\n",
        "\n",
        "# Select features\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=5)\n",
        "selector.fit(feature_matrix, labels)\n",
        "\n",
        "# Get selected indices\n",
        "selected_indices = np.argsort(selector.scores_)[::-1]\n",
        "\n",
        "# Rank features\n",
        "ranked_features = [f\"Feature {i+1}\" for i in selected_indices]\n",
        "\n",
        "# Print ranked features\n",
        "print(\"Ranked Features:\")\n",
        "for i, feature in enumerate(ranked_features):\n",
        "  print(f\"{i+1}: {feature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c835da-f932-4c18-b2be-c919a151471f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ranked Texts by Similarity:\n",
            "                                                Text  Similarity\n",
            "3  ðŸ˜Š Great experience with their customer service! ðŸ˜ƒ    0.584360\n",
            "0                 I love this product! It's amazing.    0.468316\n",
            "5         Just received my order and it's perfect! ðŸŽ‰    0.358053\n",
            "6  This new feature is amazing! Can't wait to exp...    0.257360\n",
            "7  Feeling frustrated with the app's performance ...    0.208661\n",
            "8  Spent the day outdoors, feeling blissful and c...    0.151887\n",
            "4                 I can't believe how bad this is. ðŸ˜¡    0.094290\n",
            "2           Neutral comment with no strong feelings.    0.081141\n",
            "1                       This is terrible, I hate it!   -0.030733\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "\n",
        "# Sample texts\n",
        "sample_text = [\n",
        "    \"Absolutely enamored with this product! It's a game-changer.\",\n",
        "    \"I despise this, it's a complete disappointment.\",\n",
        "    \"Sharing a neutral opinion with no strong sentiment attached.\",\n",
        "    \"ðŸ˜Š Exceptional experience with their customer service! ðŸ˜ƒ\",\n",
        "    \"I'm appalled at how dreadful this is. ðŸ˜¡\",\n",
        "    \"Just received my order and it's perfect! ðŸŽ‰\",\n",
        "    \"This new feature is amazing! Can't wait to explore it. ðŸ”¥\",\n",
        "    \"Feeling frustrated with the app's performance today. ðŸ˜¤\",\n",
        "    \"Spent the day outdoors, feeling blissful and content. ðŸŒžðŸ˜Œ\",\n",
        "]\n",
        "# Query\n",
        "query_text = \"Searching for a high-quality product with great service.\"\n",
        "\n",
        "# Load BERT model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Get embeddings\n",
        "query_embed = model.encode(query_text, convert_to_tensor=True)\n",
        "text_embed = model.encode(texts, convert_to_tensor=True)\n",
        "\n",
        "# Calculate similarity\n",
        "similarities = util.pytorch_cos_sim(query_embed, text_embed)[0]\n",
        "\n",
        "# Create dataframe and rank\n",
        "df = pd.DataFrame({'Text': texts, 'Similarity': similarities})\n",
        "df = df.sort_values(by='Similarity', ascending=False)\n",
        "print(\"\\nRanked Texts by Similarity:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Learning Experience: Extracting features from text provided good exposure to techniques like bag-of-words, TF-IDF, n-grams and BERT embeddings. Understanding how to generate numerical representations from text was very beneficial.\n",
        "Challenges: The time provided was not sufficient to fully explore implementing the techniques on real datasets.\n",
        "Relevance to NLP: Feature extraction is a crucial first step in many NLP tasks. These exercises provided a solid intro to commonly used techniques for generating useful text features.\n",
        "Overall, the exercises served as a good introduction to feature engineering for NLP. Hands-on work with real data would further improve learning. Feature extraction is an integral part of the NLP workflow.\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "18358610-29fb-4dc9-b001-08d193af7c02"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nLearning Experience: Extracting features from text provided good exposure to techniques like bag-of-words, TF-IDF, n-grams and BERT embeddings. Understanding how to generate numerical representations from text was very beneficial.\\nChallenges: The time provided was not sufficient to fully explore implementing the techniques on real datasets.\\nRelevance to NLP: Feature extraction is a crucial first step in many NLP tasks. These exercises provided a solid intro to commonly used techniques for generating useful text features.\\nOverall, the exercises served as a good introduction to feature engineering for NLP. Hands-on work with real data would further improve learning. Feature extraction is an integral part of the NLP workflow.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}